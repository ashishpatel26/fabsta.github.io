---
title: "HBase best practice"
description: "Overview of best practices for Apache HBase"
category: Hadoop
tags: [hadoop, storage]
sidebar:
  nav: "new_side"
---


# Best practices## Component setup### RegionServer and DataNodesshould run on same node, because* will persist to DataNode on same machine* RegionServer has access to local data[http://stackoverflow.com/questions/13741946/role-of-datanode-regionserver-in-hbase-hadoop-integration](http://stackoverflow.com/questions/13741946/role-of-datanode-regionserver-in-hbase-hadoop-integration)### Region serverNumber of region servers: based on memstore size + amount of RAMNumber of regions: (number of region servers - 1) * number of logical CPUsRegionServer JVM limited to 12GB to minimize long GC phases## Data model### Tablesminimize # of tables to reduce/remove joins### Row keysmake use of data locality ([source](http://hbase.apache.org/0.94/book/rowkey.design.html))
* ideal key should distribute data evenly across cluster* key-based balancer* [http://www.appfirst.com/blog/best-practices-for-managing-hbase-in-a-high-write-environment/](http://www.appfirst.com/blog/best-practices-for-managing-hbase-in-a-high-write-environment/)* [http://www.ericsson.com/research-blog/data-knowledge/horizontal-scalability-hbase/](http://www.ericsson.com/research-blog/data-knowledge/horizontal-scalability-hbase/)#### region-specific keys (salted row-keys)[http://blog.cloudera.com/blog/2015/06/how-to-scan-salted-apache-hbase-tables-with-region-specific-key-ranges-in-mapreduce/](http://blog.cloudera.com/blog/2015/06/how-to-scan-salted-apache-hbase-tables-with-region-specific-key-ranges-in-mapreduce/)#### Column families (CF)Make names as short as possible (but not shorter): e.g. "d" ([http://hbase.apache.org/0.94/book/rowkey.design.html](http://hbase.apache.org/0.94/book/rowkey.design.html))##### how many column families?not more than 2-3 ([http://hbase.apache.org/0.94/book/number.of.cfs.html](http://hbase.apache.org/0.94/book/number.of.cfs.html))uneven data amounts in CF cause too many Hfiles to be written
* when flush threshold of one CF is reached
* all other CFs will be flushed as well⇒	having 1 CF is "best" schema##### attribute nameskeep names short ([http://hbase.apache.org/0.94/book/rowkey.design.html](http://hbase.apache.org/0.94/book/rowkey.design.html))#### Things to consider##### Memstore flushes* think about when flush should be triggered* [http://blog.sematext.com/2012/07/16/hbase-memstore-what-you-should-know/](http://blog.sematext.com/2012/07/16/hbase-memstore-what-you-should-know/)##### Hlog & memstore flush sizekeep hbase.regionsever.hlog.blocksize * hbase.regionserver.maxlogs just a bit above hbase.regionserver.global.memstore.lowerLimit * HBASE_HEAPSIZE##### Compression* reduces space and disk & network I/O* compression should not be a bottleneck* favor compression speed over compression ratio (SNAPPY)##### Failurewhy? node gets hammered and they starts swappingsolution: have fixed number of regionsdistribute evenly across region servers (req. estimating)monitor & keep track of 
* CPU* I/O* network latency* bandwithto avoid: node to lose contact to master, another server picks up the load and becomes over-burdened ##### Things to keep in mind* Hbase and MapReduce in same cluster* might lead to unpredictable latencies* Hbase is CPU and memory intense with sporadic large I/O access* MapReduce is primarily I/O bound with fixed memory sporadic CPU##Storage### auto-compactiondefault: every 24 hours after start of Hbase. better: set to off-peak time## How to benchmark[http://www.ericsson.com/research-blog/data-knowledge/hbase-performance-tuners/](http://www.ericsson.com/research-blog/data-knowledge/hbase-performance-tuners/)## General configurationput correctly configured hbase conf in CLASSPATH## Queries### for column scanning[http://www.appfirst.com/blog/best-practices-for-managing-hbase-in-a-high-write-environment/](http://www.appfirst.com/blog/best-practices-for-managing-hbase-in-a-high-write-environment/)### find most recent version of valueuse reverse timestamps ([key][reverse_timestamp]). A scan will give most recent value first ([http://hbase.apache.org/0.94/book/rowkey.design.html](http://hbase.apache.org/0.94/book/rowkey.design.html))## Monitoring### Node starts swapping→ might miss a heartbeat and Zookeeper drops it from cluster### Tools[https://sematext.com/spm/](https://sematext.com/spm/)### HBase webGui```
localhost:16010
```#Integration with other Hadoop components## Zookeeperis used for leader selection (http://hbase.apache.org/0.94/book/zookeeper.html)## NTP and DNSproper clocks on all nodes required for synchronization.# References## Blog posts### High write environment: [http://www.appfirst.com/blog/best-practices-for-managing-hbase-in-a-high-write-environment/](http://www.appfirst.com/blog/best-practices-for-managing-hbase-in-a-high-write-environment/)### I/O (Hfile)* [http://blog.cloudera.com/blog/2012/06/hbase-io-hfile-input-output/](http://blog.cloudera.com/blog/2012/06/hbase-io-hfile-input-output/)* [https://blog.cloudera.com/blog/2011/04/hbase-dos-and-donts/](https://blog.cloudera.com/blog/2011/04/hbase-dos-and-donts/)* [http://blog.sematext.com/2012/07/16/hbase-memstore-what-you-should-know/](http://blog.sematext.com/2012/07/16/hbase-memstore-what-you-should-know/)* [https://www-01.ibm.com/support/knowledgecenter/SSWSR9_11.5.0/com.ibm.swg.im.mdmhs.pmebi.doc/topics/bestpractice_loadhbase.html](https://www-01.ibm.com/support/knowledgecenter/SSWSR9_11.5.0/com.ibm.swg.im.mdmhs.pmebi.doc/topics/bestpractice_loadhbase.html)## Hbase BookSchema design: [http://hbase.apache.org/0.94/book/schema.html?cm_mc_uid=71779097810314486356299&cm_mc_sid_50200000=1454495034](http://hbase.apache.org/0.94/book/schema.html?cm_mc_uid=71779097810314486356299&cm_mc_sid_50200000=1454495034)## PresentationsHBase operations practices: [http://www.slideshare.net/vanuganti/hbase-hadoop-hbaseoperationspractices](http://www.slideshare.net/vanuganti/hbase-hadoop-hbaseoperationspractices)## Mailing list[https://hbase.apache.org/mail-lists.html](https://hbase.apache.org/mail-lists.html)